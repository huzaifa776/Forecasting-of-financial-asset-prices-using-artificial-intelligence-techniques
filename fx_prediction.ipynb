{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load The Data\n",
    "df = pd.read_csv(\"EURCHF.csv\", index_col=0, parse_dates=True)\n",
    "df = df.drop(['Adj Close'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the stock price chart\n",
    "figure(figsize=(15, 8))\n",
    "plt.plot(df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING\n",
    "\n",
    "# Momentum\n",
    "df['AO'] = ta.ao(df.High, df.Low)\n",
    "df['CCI'] = ta.cci(df.High, df.Low, df.Close, 13)\n",
    "df['RSI'] = ta.rsi(df.Close, 13)\n",
    "\n",
    "# Overlap\n",
    "df['EMA'] = ta.ema(df.Close, 20) / df.Close - 1\n",
    "df['SMA'] = ta.sma(df.Close, 20) / df.Close - 1\n",
    "df['SINWMA'] = ta.sinwma(df.Close, 20) / df.Close - 1\n",
    "\n",
    "# Stats\n",
    "df['Z'] = ta.zscore(df.Close, 50)\n",
    "\n",
    "# Trend\n",
    "df['AROON'] = ta.aroon(df.High, df.Low, 50).iloc[:,-1]\n",
    "df['CHOP'] = ta.chop(df.High, df.Low, df.Close, 50)\n",
    "\n",
    "# Volatility\n",
    "df['ABERRATION'] = ta.aberration(df.High, df.Low, df.Close, 50).iloc[:,-1]\n",
    "df['MASS'] = ta.massi(df.High, df.Low, 50)\n",
    "\n",
    "# Volume\n",
    "df['ADOSC'] = ta.adosc(df.High, df.Low, df.Close, df.Volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET PREPARATION\n",
    "df['NEXT DAY RETURN'] = df['Close'].pct_change(1).shift(-1) * 100\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y, Train/Test Split\n",
    "split_ratio = 0.8\n",
    "split_idx = int(len(df)*split_ratio)\n",
    "\n",
    "# Regression\n",
    "X_train, Y_train = df.iloc[:split_idx, :-1], df.iloc[:split_idx, -1]\n",
    "X_test, Y_test   = df.iloc[split_idx:, :-1], df.iloc[split_idx:, -1]\n",
    "\n",
    "# Classification (direction of price movement)\n",
    "Y_train_class = (Y_train >= 0)*2.0 - 1.0\n",
    "Y_test_class  = (Y_test  >= 0)*2.0 - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wide variety of non-NN ML models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm          import SVC, SVR\n",
    "from sklearn.neighbors    import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree         import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble     import AdaBoostClassifier, AdaBoostRegressor, RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "# Load relevant performance metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, f1_score, roc_auc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wide variety of Machine Learning models\n",
    "LR = LinearRegression()\n",
    "LR_c = LogisticRegression()\n",
    "\n",
    "SVM = SVR()\n",
    "SVM_c = SVC()\n",
    "\n",
    "KNN = KNeighborsRegressor()\n",
    "KNN_c = KNeighborsClassifier()\n",
    "\n",
    "DT = DecisionTreeRegressor()\n",
    "DT_c = DecisionTreeClassifier()\n",
    "\n",
    "ADA = AdaBoostRegressor()\n",
    "ADA_c = AdaBoostClassifier()\n",
    "\n",
    "RF = RandomForestRegressor()\n",
    "RF_c = RandomForestClassifier()\n",
    "\n",
    "GB = GradientBoostingRegressor()\n",
    "GB_c = GradientBoostingClassifier()\n",
    "\n",
    "regressors = [LR, SVM, KNN, DT, ADA, RF, GB]\n",
    "classifiers = [SVM_c, KNN_c, DT_c, ADA_c, RF_c, GB_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_mae = {}\n",
    "classification_acc = {}\n",
    "classification_auc = {}\n",
    "\n",
    "\n",
    "# Train and evaluate regressors\n",
    "for regressor in regressors:\n",
    "    name = str(regressor)[:-2]\n",
    "    regressor.fit(X_train, Y_train)\n",
    "    mae = mean_absolute_error(Y_test, regressor.predict(X_test))\n",
    "    regression_mae[name] = mae\n",
    "\n",
    "# Train and evaluate classifiers\n",
    "for classifier in classifiers:\n",
    "    name = str(classifier)[:-2]\n",
    "    classifier.fit(X_train, Y_train_class)\n",
    "    \n",
    "    acc = accuracy_score(Y_test_class, classifier.predict(X_test))\n",
    "    auc = roc_auc_score(Y_test_class, classifier.predict(X_test))\n",
    "    \n",
    "    classification_acc[name] = acc\n",
    "    classification_auc[name] = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all nessesary Deep Learning Libraries\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Networks Need Scaled Data\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train_scaled = ss.transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "# Simple ANN (MLP) - Regression\n",
    "ANN = Sequential()\n",
    "ANN.add(Dense(12, input_shape=(X_train_scaled.shape[1],), activation='linear'))\n",
    "ANN.add(Dense(8, activation='linear'))\n",
    "ANN.add(Dense(4, activation='linear'))\n",
    "ANN.add(Dense(2, activation='linear'))\n",
    "ANN.add(Dense(1, activation='linear'))\n",
    "ANN.compile(loss = \"mean_absolute_error\", optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "ANN.fit(X_train_scaled, Y_train, epochs=100, validation_data=(X_test_scaled, Y_test), callbacks=[earlyStopping, mcp_save, reduce_lr_loss])\n",
    "\n",
    "mae = mean_absolute_error(Y_test, ANN.predict(X_test_scaled))\n",
    "regression_mae[\"ANN\"] = mae\n",
    "\n",
    "\n",
    "# Simple ANN (MLP) - Classification\n",
    "ANN = Sequential()\n",
    "ANN.add(Dense(12, input_shape=(X_train_scaled.shape[1],), activation='linear'))\n",
    "ANN.add(Dense(8, activation='linear'))\n",
    "ANN.add(Dense(4, activation='linear'))\n",
    "ANN.add(Dense(2, activation='relu'))\n",
    "ANN.add(Dense(1, activation='sigmoid'))\n",
    "ANN.compile(loss = \"binary_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "ANN.fit(X_train_scaled, Y_train_class, epochs=100, validation_data=(X_test_scaled, Y_test_class), callbacks=[earlyStopping, mcp_save, reduce_lr_loss])\n",
    "\n",
    "acc = accuracy_score(Y_test_class, (ANN.predict(X_test_scaled) > 0.5)*2.0 - 1.0)\n",
    "auc = roc_auc_score(Y_test_class, (ANN.predict(X_test_scaled) > 0.5)*2.0 - 1.0)\n",
    "\n",
    "classification_acc[\"ANN\"] = acc\n",
    "classification_auc[\"ANN\"] = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_scaled_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# lstm - Regression\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(12, input_shape=(1, X_train_scaled_lstm.shape[2]), activation='linear'))\n",
    "lstm.add(Dense(8, activation='linear'))\n",
    "lstm.add(Dense(4, activation='linear'))\n",
    "lstm.add(Dense(2, activation='linear'))\n",
    "lstm.add(Dense(1, activation='linear'))\n",
    "lstm.compile(loss = \"mean_absolute_error\", optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "lstm.fit(X_train_scaled_lstm, Y_train, epochs=100, validation_data=(X_test_scaled_lstm, Y_test), callbacks=[earlyStopping, mcp_save, reduce_lr_loss])\n",
    "\n",
    "mae = mean_absolute_error(Y_test, lstm.predict(X_test_scaled_lstm))\n",
    "regression_mae[\"lstm\"] = mae\n",
    "\n",
    "\n",
    "# Simple ANN - Classification\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(12, input_shape=(1, X_train_scaled_lstm.shape[2]), activation='linear'))\n",
    "lstm.add(Dense(8, activation='linear'))\n",
    "lstm.add(Dense(4, activation='linear'))\n",
    "lstm.add(Dense(2, activation='relu'))\n",
    "lstm.add(Dense(1, activation='sigmoid'))\n",
    "lstm.compile(loss = \"binary_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "lstm.fit(X_train_scaled_lstm, Y_train_class, epochs=100, validation_data=(X_test_scaled_lstm, Y_test_class), callbacks=[earlyStopping, mcp_save, reduce_lr_loss])\n",
    "\n",
    "acc = accuracy_score(Y_test_class, (lstm.predict(X_test_scaled_lstm) > 0.5)*2.0 - 1.0)\n",
    "auc = roc_auc_score(Y_test_class, (lstm.predict(X_test_scaled_lstm) > 0.5)*2.0 - 1.0)\n",
    "\n",
    "classification_acc[\"lstm\"] = acc\n",
    "classification_auc[\"lstm\"] = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "predict_from = 1\n",
    "predict_until = 1\n",
    "lookback = 3\n",
    "\n",
    "# Regression\n",
    "\n",
    "clf = ak.TimeseriesForecaster(\n",
    "    lookback=lookback,\n",
    "    predict_from=predict_from,\n",
    "    predict_until=predict_until,\n",
    "    max_trials=1,\n",
    "    objective=\"val_loss\",\n",
    ")\n",
    "\n",
    "# Train the TimeSeriesForecaster with train data\n",
    "clf.fit(\n",
    "    x=X_train_scaled,\n",
    "    y=Y_train,\n",
    "    validation_data=(X_test_scaled, Y_test),\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    ")\n",
    "\n",
    "# Predict with the best model(includes original training data).\n",
    "mae = mean_absolute_error(Y_test, lstm.predict(X_test_scaled_lstm))\n",
    "regression_mae[\"autokeras\"] = mae\n",
    "\n",
    "\n",
    "# Classification\n",
    "\n",
    "clf_class = ak.TimeseriesForecaster(\n",
    "    lookback=lookback,\n",
    "    predict_from=predict_from,\n",
    "    predict_until=predict_until,\n",
    "    max_trials=1,\n",
    "    objective=\"val_loss\",\n",
    ")\n",
    "\n",
    "# Train the TimeSeriesForecaster with train data\n",
    "clf_class.fit(\n",
    "    x=X_train_scaled,\n",
    "    y=Y_train,\n",
    "    validation_data=(X_test_scaled, Y_test),\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    ")\n",
    "\n",
    "# Predict with the best model(includes original training data).\n",
    "acc = accuracy_score(Y_test_class, (clf_class.predict(X_test_scaled_lstm) > 0.5)*2.0 - 1.0)\n",
    "auc = roc_auc_score(Y_test_class, (clf_class.predict(X_test_scaled_lstm) > 0.5)*2.0 - 1.0)\n",
    "\n",
    "classification_acc[\"autokeras\"] = acc\n",
    "classification_auc[\"autokeras\"] = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(regression_mae.values(), index=regression_mae.keys()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(classification_acc.values(), index=classification_acc.keys()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(classification_auc.values(), index=classification_auc.keys()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('finRL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d627f736ce1165924419ff8e4afbba69a186716e81617c9e71f428ccf92a5e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
